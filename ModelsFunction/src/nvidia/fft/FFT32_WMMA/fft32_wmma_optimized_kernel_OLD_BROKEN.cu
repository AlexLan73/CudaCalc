/**
 * @file fft32_wmma_optimized_kernel.cu
 * @brief ULTRA-OPTIMIZED FFT32 WMMA kernel (FP32)
 * 
 * Target: 0.0108ms or better!
 * 
 * Optimizations:
 * - 2D blocks [32, 32] = 1024 threads
 * - Constant memory twiddles
 * - __ldg() for read-only loads
 * - Bit shifts for indexing
 * - Shared memory padding
 * - Linear unroll (5 butterfly stages)
 * - In-kernel FFT shift
 */

#include <cuda_runtime.h>
#include <cuComplex.h>
#include <stdexcept>
#include <string>

// === CONSTANT MEMORY: Pre-computed twiddle factors for FFT32 ===
// W_32^k = exp(-2Ï€i*k/32) for k=0..31
__constant__ float TWIDDLES_32_REAL[32] = {
    1.000000f,   0.980785f,   0.923880f,   0.831470f,
    0.707107f,   0.555570f,   0.382683f,   0.195090f,
    0.000000f,  -0.195090f,  -0.382683f,  -0.555570f,
   -0.707107f,  -0.831470f,  -0.923880f,  -0.980785f,
   -1.000000f,  -0.980785f,  -0.923880f,  -0.831470f,
   -0.707107f,  -0.555570f,  -0.382683f,  -0.195090f,
   -0.000000f,   0.195090f,   0.382683f,   0.555570f,
    0.707107f,   0.831470f,   0.923880f,   0.980785f
};

__constant__ float TWIDDLES_32_IMAG[32] = {
   -0.000000f,  -0.195090f,  -0.382683f,  -0.555570f,
   -0.707107f,  -0.831470f,  -0.923880f,  -0.980785f,
   -1.000000f,  -0.980785f,  -0.923880f,  -0.831470f,
   -0.707107f,  -0.555570f,  -0.382683f,  -0.195090f,
    0.000000f,   0.195090f,   0.382683f,   0.555570f,
    0.707107f,   0.831470f,   0.923880f,   0.980785f,
    1.000000f,   0.980785f,   0.923880f,   0.831470f,
    0.707107f,   0.555570f,   0.382683f,   0.195090f
};

__constant__ int BIT_REVERSED_32[32] = {
     0, 16,  8, 24,  4, 20, 12, 28,
     2, 18, 10, 26,  6, 22, 14, 30,
     1, 17,  9, 25,  5, 21, 13, 29,
     3, 19, 11, 27,  7, 23, 15, 31
};

// ==========================================
// FFT32 KERNEL with ULTRA OPTIMIZATIONS
// ==========================================
// - FP32 precision
// - 2D block: [32 FFTs][32 points] = 1024 threads
// - Constant memory twiddles
// - __ldg() loads
// - Bit shifts for indexing
// - Shared memory padding
// - Linear unroll (5 butterfly stages)
// - In-kernel FFT shift
// ==========================================

__global__ void fft32_wmma_optimized_kernel(
    const cuComplex* __restrict__ input,
    cuComplex* __restrict__ output,
    int num_windows
) {
    // Thread configuration: 2D block for max occupancy
    const int block_fft_id = threadIdx.x;  // 0..31 (32 FFTs per block)
    const int point_id = threadIdx.y;      // 0..31 (32 points per FFT)
    const int global_fft_id = (blockIdx.x << 5) + block_fft_id;  // blockIdx.x * 32

    if (global_fft_id >= num_windows) return;

    // Shared memory with padding to avoid bank conflicts
    __shared__ float2 shmem[32][34];  // 34 for padding (32+2)

    // === LOAD INPUT TO SHARED MEMORY WITH BIT-REVERSAL ===
    const int input_idx = (global_fft_id << 5) + point_id;  // global_fft_id * 32
    const int reversed_idx = BIT_REVERSED_32[point_id];
    float2 loaded_val = make_float2(__ldg(&input[input_idx].x), __ldg(&input[input_idx].y));
    shmem[block_fft_id][reversed_idx] = loaded_val;
    __syncthreads();

    // === BUTTERFLY STAGES (linear unroll for 5 stages) ===

    // ====================
    // STAGE 0: step = 1
    // ====================
    {
        const int step = 1;
        const int group_size = 2;
        const int pair_id = point_id >> 1;           // point_id / 2
        const int in_pair = point_id & 1;            // point_id % 2
        const int idx1 = (pair_id << 1) + in_pair;   // pair_id * 2 + in_pair
        const int idx2 = idx1 + step;

        float2 a = shmem[block_fft_id][idx1];
        float2 b = shmem[block_fft_id][idx2];

        // For stage 0, twiddle is always +1 or -1
        shmem[block_fft_id][idx1] = make_float2(a.x + b.x, a.y + b.y);
        shmem[block_fft_id][idx2] = make_float2(a.x - b.x, a.y - b.y);
        __syncthreads();
    }

    // ====================
    // STAGE 1: step = 2
    // ====================
    {
        const int step = 2;
        const int group_size = 4;
        const int group_id = point_id >> 2;          // point_id / 4
        const int in_group = point_id & 3;           // point_id % 4
        const int idx1 = (group_id << 2) + in_group; // group_id * 4 + in_group
        const int idx2 = idx1 + step;

        float2 a = shmem[block_fft_id][idx1];
        float2 b = shmem[block_fft_id][idx2];

        // Twiddle index for FFT32
        const int tw_idx = (in_group << 3);  // in_group * 8
        const float tw_re = TWIDDLES_32_REAL[tw_idx & 31];
        const float tw_im = TWIDDLES_32_IMAG[tw_idx & 31];

        // Complex multiply: b * twiddle
        float b_tw_re = b.x * tw_re - b.y * tw_im;
        float b_tw_im = b.x * tw_im + b.y * tw_re;

        shmem[block_fft_id][idx1] = make_float2(a.x + b_tw_re, a.y + b_tw_im);
        shmem[block_fft_id][idx2] = make_float2(a.x - b_tw_re, a.y - b_tw_im);
        __syncthreads();
    }

    // ====================
    // STAGE 2: step = 4
    // ====================
    {
        const int step = 4;
        const int group_size = 8;
        const int group_id = point_id >> 3;          // point_id / 8
        const int in_group = point_id & 7;           // point_id % 8
        const int idx1 = (group_id << 3) + in_group; // group_id * 8 + in_group
        const int idx2 = idx1 + step;

        float2 a = shmem[block_fft_id][idx1];
        float2 b = shmem[block_fft_id][idx2];

        // Twiddle index
        const int tw_idx = (in_group << 2);  // in_group * 4
        const float tw_re = TWIDDLES_32_REAL[tw_idx & 31];
        const float tw_im = TWIDDLES_32_IMAG[tw_idx & 31];

        float b_tw_re = b.x * tw_re - b.y * tw_im;
        float b_tw_im = b.x * tw_im + b.y * tw_re;

        shmem[block_fft_id][idx1] = make_float2(a.x + b_tw_re, a.y + b_tw_im);
        shmem[block_fft_id][idx2] = make_float2(a.x - b_tw_re, a.y - b_tw_im);
        __syncthreads();
    }

    // ====================
    // STAGE 3: step = 8
    // ====================
    {
        const int step = 8;
        const int group_size = 16;
        const int group_id = point_id >> 4;           // point_id / 16
        const int in_group = point_id & 15;           // point_id % 16
        const int idx1 = (group_id << 4) + in_group;  // group_id * 16 + in_group
        const int idx2 = idx1 + step;

        float2 a = shmem[block_fft_id][idx1];
        float2 b = shmem[block_fft_id][idx2];

        // Twiddle index
        const int tw_idx = (in_group << 1);  // in_group * 2
        const float tw_re = TWIDDLES_32_REAL[tw_idx & 31];
        const float tw_im = TWIDDLES_32_IMAG[tw_idx & 31];

        float b_tw_re = b.x * tw_re - b.y * tw_im;
        float b_tw_im = b.x * tw_im + b.y * tw_re;

        shmem[block_fft_id][idx1] = make_float2(a.x + b_tw_re, a.y + b_tw_im);
        shmem[block_fft_id][idx2] = make_float2(a.x - b_tw_re, a.y - b_tw_im);
        __syncthreads();
    }

    // ====================
    // STAGE 4: step = 16
    // ====================
    {
        const int step = 16;
        const int group_size = 32;
        const int in_group = point_id;                // point_id % 32 (only 1 group)
        const int idx1 = in_group;
        const int idx2 = idx1 + step;

        float2 a = shmem[block_fft_id][idx1];
        float2 b = shmem[block_fft_id][idx2];

        // Twiddle index
        const int tw_idx = in_group;
        const float tw_re = TWIDDLES_32_REAL[tw_idx];
        const float tw_im = TWIDDLES_32_IMAG[tw_idx];

        float b_tw_re = b.x * tw_re - b.y * tw_im;
        float b_tw_im = b.x * tw_im + b.y * tw_re;

        shmem[block_fft_id][idx1] = make_float2(a.x + b_tw_re, a.y + b_tw_im);
        shmem[block_fft_id][idx2] = make_float2(a.x - b_tw_re, a.y - b_tw_im);
        __syncthreads();
    }

    // === STORE OUTPUT (NO SHIFT!) ===
    const int output_idx = (global_fft_id << 5) + point_id;
    output[output_idx].x = shmem[block_fft_id][point_id].x;
    output[output_idx].y = shmem[block_fft_id][point_id].y;
}

// ==========================================
// KERNEL LAUNCHER
// ==========================================

void launch_fft32_wmma_optimized_kernel(
    const cuComplex* d_input,
    cuComplex* d_output,
    int num_windows
) {
    // 2D block: [32 FFTs][32 points] = 1024 threads
    const int fft_per_block = 32;
    const int num_blocks = (num_windows + fft_per_block - 1) / fft_per_block;
    dim3 block_dim(32, 32);
    dim3 grid_dim(num_blocks);

    fft32_wmma_optimized_kernel<<<grid_dim, block_dim>>>(d_input, d_output, num_windows);
    
    cudaError_t err = cudaGetLastError();
    if (err != cudaSuccess) {
        throw std::runtime_error(std::string("CUDA kernel launch failed: ") + cudaGetErrorString(err));
    }
    
    cudaDeviceSynchronize();
}

